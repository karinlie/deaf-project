from fastapi import FastAPI, UploadFile, File
import tensorflow as tf
import numpy as np
import io
import librosa
from fastapi.middleware.cors import CORSMiddleware
from pydub import AudioSegment
import whisper
import os
import whisper
import serial
import time
from fastapi import APIRouter
from yolo_backend import object_function, get_latest_detections

from fastapi.responses import JSONResponse
import json


print("üöÄ Laster inn Whisper-modellen...")
whisper_model = whisper.load_model("base")  # Velg "tiny", "small", "medium" eller "large"
print("‚úÖ Whisper-modellen er lastet!")


app = FastAPI()
router = APIRouter()

# ‚úÖ Aktiver CORS slik at frontend (localhost:5173) kan snakke med backend (localhost:8000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Eller ["http://localhost:5173"] for mer sikkerhet
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

arduino_port = "COM4"  # Endre til riktig port (Linux: "/dev/ttyUSB0", Mac: "/dev/cu.usbserial")
baud_rate = 9600  # M√• matche Arduino-koden

try:
    arduino = serial.Serial(arduino_port, baud_rate, timeout=1)
    time.sleep(2)  # Vent p√• at Arduino starter opp
    print("‚úÖ Arduino tilkoblet!")
except Exception as e:
    print(f"‚ùå Feil ved tilkobling til Arduino: {e}")


@app.get("/detection/")
async def detect_objects():
    result = get_latest_detections()
    detections = result.get("detections", [])

    print("üì∏ YOLO Resultat:", detections)

    for detection in detections:
        if detection["object"] == "human":
            confidence = detection["confidence"]
            bbox = detection["bbox"][0]  # Vi tar bare √©n boks for n√•
            x1, y1, x2, y2 = bbox
            center_x = (x1 + x2) / 2

            print(f"üë§ Person oppdaget midt p√• x = {center_x:.2f}")

            if center_x < 320:
                print("üîä Person til VENSTRE ‚Äì sender 'V1'")
                arduino.write(b'1')  # Venstre vibrasjon
            else:
                print("üîä Person til H√òYRE ‚Äì sender 'V2'")
                arduino.write(b'2')  # H√∏yre vibrasjon

            return JSONResponse(content={
                "movement_alert": True,
                "status": "Menneske detektert og rett vibrasjon aktivert!",
                "confidence": confidence,
                "position": "left" if center_x < 320 else "right",
                "timestamp": result.get("timestamp")
            })

    return JSONResponse(content={
        "movement_alert": False,
        "status": "Ingen mennesker detektert.",
        "timestamp": result.get("timestamp")
    })

def yamnet_predict(audio):
        
    model_path = "C:/Users/Karin/alarm-detector/models"  # Sjekk at stien er riktig
    try:
        yamnet_model = tf.saved_model.load(model_path)
        print("‚úÖ  yamnet Modellen er lastet inn!")
    except Exception as e:
        print(f"‚ùå Feil ved lasting av modellen: {e}")
    yamnet_predict_fn = yamnet_model.signatures["serving_default"]  # Bruk riktig signatur
    return yamnet_predict_fn

# ‚úÖ Funksjon for √• forberede lydfilen
def preprocess_audio(audio_bytes):
    """Konverterer en lydfil til 16kHz mono og returnerer en normalisert waveform."""
    try:
        print("üöÄ Starter lydprosessering...")
        print(f"üìÇ Mottatt lydst√∏rrelse: {len(audio_bytes)} bytes")

        # üéµ Lagre filen for debugging
        test_file = "test_received.wav"
        with open(test_file, "wb") as f:
            f.write(audio_bytes)
        print(f"‚úÖ Lydfil lagret som {test_file}")

        # üéµ Konverter fra WEBM til WAV med pydub
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="webm")
        audio = audio.set_frame_rate(16000).set_channels(1)  # Konverter til 16kHz mono

        # üîç Konverter til NumPy-array for librosa
        audio_array = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0  # Normalisering [-1, 1]

        # üöÄ Konverter til TensorFlow-format
        waveform = tf.convert_to_tensor(np.expand_dims(audio_array, axis=0), dtype=tf.float32)

        print(f"‚úÖ Lyd konvertert: {waveform.shape}")  # Debugging
        return waveform

    except Exception as e:
        print(f"‚ùå Feil under lydprosessering: {str(e)}")
        return None

# ‚úÖ API-endepunkt for √• gj√∏re prediksjon p√• lydfiler
@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    try:
        # üéµ Les lydfilen
        audio_bytes = await file.read()
        print(f"üìÇ Lydfil mottatt: {len(audio_bytes)} bytes")  # Sjekk at vi mottar lydfilen

        # üéµ Lagre filen for testing
        with open("test_received.wav", "wb") as f:
            f.write(audio_bytes)

        print("‚úÖ Lydfil lagret som 'test_received.wav' ‚Äì Sjekk om den kan spilles av!")

        waveform = preprocess_audio(audio_bytes)
        print(f"üîÑ Prosessert lyd - Shape: {waveform.shape}")  # Sjekk at waveform er riktig

        # üîç Kj√∏r YAMNet-modellen
        yamnet_model = yamnet_predict
        output_dict = yamnet_model(waveform)
        scores = output_dict["predictions"]

        predicted_class = tf.argmax(scores, axis=-1).numpy()[0]
        confidence = tf.reduce_max(scores).numpy()

        print(f"üéØ Predikert klasse: {predicted_class} (Sannsynlighet: {confidence:.2f})")  # Logg resultat

        return {"class_id": int(predicted_class), "confidence": float(confidence)}

    except Exception as e:
        print(f"‚ö†Ô∏è FEIL: {str(e)}")
        return {"error": str(e)}

@app.post("/transcribe/")
async def transcribe_audio(file: UploadFile = File(...)):
    try:
        # üöÄ Opprett "temp/" mappe hvis den ikke finnes
        os.makedirs("temp", exist_ok=True)

        file_location = f"temp/{file.filename}"
        
        # üéµ Lagre filen
        with open(file_location, "wb") as buffer:
            buffer.write(await file.read())

        print(f"üìÇ Fil lagret: {file_location}")

        # üîç Kj√∏r Whisper-modellen
        result = whisper_model.transcribe(file_location)
        transcription = result["text"]

        print(f"üìù Transkribert tekst: {transcription}")

        return {"text": transcription}

    except Exception as e:
        print(f"‚ö†Ô∏è FEIL: {str(e)}")
        return {"error": str(e)}


